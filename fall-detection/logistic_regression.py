import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_curve, roc_auc_score
)
from sklearn.preprocessing import LabelEncoder, StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt

# ðŸ”¹ 1. Charger le dataset
data = pd.read_csv("binaire.csv")
data = data.dropna()
data = data.drop(columns=['TimeStamp', 'Sample No', 'Sensor ID'])

# ðŸ”¹ 2. Ã‰quilibrage des classes
data = data.groupby("Label").apply(lambda x: x.sample(n=117564, random_state=42)).reset_index(drop=True)

# ðŸ”¹ 3. SÃ©parer features et labels
X = data.drop("Label", axis=1).values
y = data["Label"].values

# ðŸ”¹ 4. Encodage des labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# ðŸ”¹ 5. Normalisation des features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ðŸ”¹ 6. Diviser en donnÃ©es d'entraÃ®nement et de test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# ðŸ”¹ 7. CrÃ©er et entraÃ®ner le modÃ¨le
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# ðŸ”¹ 8. Ã‰valuer le modÃ¨le
y_pred = model.predict(X_test)

# ðŸ”¸ Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nðŸ”¹ Accuracy: {accuracy:.2f}")

# ðŸ”¸ Classification report
print("\nðŸ”¹ Classification Report :")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# ðŸ”¸ Matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=label_encoder.classes_,
            yticklabels=label_encoder.classes_)
plt.title("Matrice de Confusion")
plt.xlabel("PrÃ©diction")
plt.ylabel("RÃ©el")
plt.show()

# ðŸ”¸ Courbe ROC
y_scores = model.predict_proba(X_test)[:, 1]  # ProbabilitÃ© pour la classe positive
fpr, tpr, thresholds = roc_curve(y_test, y_scores)
auc = roc_auc_score(y_test, y_scores)

plt.figure()
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {auc:.2f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random guess")
plt.xlabel("Taux de faux positifs (FPR)")
plt.ylabel("Taux de vrais positifs (TPR)")
plt.title("Courbe ROC - RÃ©gression Logistique")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()
